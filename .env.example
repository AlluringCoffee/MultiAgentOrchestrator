# ============================================
# Multi-Agent Orchestrator - Configuration
# ============================================
# Copy this file to .env and fill in your values

# ============================================
# HARDWARE PROFILE
# ============================================
# Options: low_end | medium | high_end
# low_end  = CPU only, cloud APIs, small models
# medium   = 8GB GPU, local 7B models
# high_end = 24GB+ GPU, large reasoning models
HARDWARE_PROFILE=medium

# ============================================
# LOCAL LLM (Ollama)
# ============================================
OLLAMA_ENDPOINT=http://localhost:11434
# Default models per profile:
# low_end:  tinyllama
# medium:   mistral:7b or llama3:8b
# high_end: deepseek-r1 or mixtral:8x7b

# ============================================
# CLOUD PROVIDERS (Optional)
# ============================================
# Groq (Fast inference, free tier)
GROQ_API_KEY=

# Google AI (Gemini)
GOOGLE_AI_API_KEY=

# OpenAI (GPT-4)
OPENAI_API_KEY=

# Anthropic (Claude)
ANTHROPIC_API_KEY=

# ============================================
# SERVER SETTINGS
# ============================================
HOST=0.0.0.0
PORT=8000
DEBUG=false
